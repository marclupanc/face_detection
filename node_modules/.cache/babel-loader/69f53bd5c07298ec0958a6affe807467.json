{"ast":null,"code":"var _jsxFileName = \"/Users/maraclupanciuc/Desktop/SmartBrain/face-detection/face_detection/src/components/Stream/Stream.jsx\",\n    _s = $RefreshSig$();\n\nimport * as faceapi from 'face-api.js';\nimport React from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nfunction Stream() {\n  _s();\n\n  const [modelsLoaded, setModelsLoaded] = React.useState(false);\n  const [captureVideo, setCaptureVideo] = React.useState(false);\n  const videoRef = React.useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = React.useRef();\n  React.useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n      Promise.all([faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL), faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL), faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL), faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)]).then(setModelsLoaded(true));\n    };\n\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices.getUserMedia({\n      video: {\n        width: 300\n      }\n    }).then(stream => {\n      let video = videoRef.current;\n      video.srcObject = stream;\n      video.play();\n    }).catch(err => {\n      console.error(\"error:\", err);\n    });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(videoRef.current);\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight\n        };\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n        const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n        canvasRef && canvasRef.current && canvasRef.current.getContext('2d').clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef && canvasRef.current && faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef && canvasRef.current && faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef && canvasRef.current && faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections);\n      }\n    }, 100);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        textAlign: 'center',\n        padding: '10px'\n      },\n      children: captureVideo && modelsLoaded ? /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: closeWebcam,\n        style: {\n          cursor: 'pointer',\n          backgroundColor: 'green',\n          color: 'white',\n          padding: '15px',\n          fontSize: '25px',\n          border: 'none',\n          borderRadius: '10px'\n        },\n        children: \"Close Webcam\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 76,\n        columnNumber: 13\n      }, this) : /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: startVideo,\n        style: {\n          cursor: 'pointer',\n          backgroundColor: 'green',\n          color: 'white',\n          padding: '15px',\n          fontSize: '25px',\n          border: 'none',\n          borderRadius: '10px'\n        },\n        children: \"Open Webcam\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 80,\n        columnNumber: 13\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 7\n    }, this), captureVideo ? modelsLoaded ? /*#__PURE__*/_jsxDEV(\"div\", {\n      children: /*#__PURE__*/_jsxDEV(\"div\", {\n        style: {\n          display: 'flex',\n          justifyContent: 'center',\n          padding: '10px'\n        },\n        children: [/*#__PURE__*/_jsxDEV(\"video\", {\n          ref: videoRef,\n          height: videoHeight,\n          width: videoWidth,\n          onPlay: handleVideoOnPlay,\n          style: {\n            borderRadius: '10px'\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 90,\n          columnNumber: 17\n        }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n          ref: canvasRef,\n          style: {\n            position: 'absolute'\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 91,\n          columnNumber: 17\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 89,\n        columnNumber: 15\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 88,\n      columnNumber: 13\n    }, this) : /*#__PURE__*/_jsxDEV(\"div\", {\n      children: \"loading...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 95,\n      columnNumber: 13\n    }, this) : /*#__PURE__*/_jsxDEV(_Fragment, {}, void 0, false)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 72,\n    columnNumber: 5\n  }, this);\n}\n\n_s(Stream, \"r7/G1Z43y30xxZApC/YFouB9GI0=\");\n\n_c = Stream;\nexport default Stream; // import {useRef, useEffect, useState} from \"react\";\n// import './stream.css'\n// import * as faceapi from 'face-api.js';import '../../face-api.min'\n// // import {faceapi} from \"../../face-api.min\";\n//\n//\n// const Stream = ({videoState, setVideoState}) => {\n//\n//   const videoRef = useRef();\n//   const [modelsLoaded, setModelsLoaded] = useState(false);\n//   const [captureVideo, setCaptureVideo] = useState(false);\n//\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       const MODEL_URL = process.env.PUBLIC_URL + '../../models';\n//\n//       Promise.all([\n//         faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n//         faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n//         faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n//         faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n//       ]).then(setModelsLoaded(true));\n//     }\n//     loadModels();\n//   }, []);\n//   return (\n//     <div>\n//\n//     </div>\n//   )\n// }\n// //   useEffect(() => {\n// //     navigator.mediaDevices.getUserMedia({ video: videoState }).then((stream) => {\n// //       videoRef.current.srcObject = stream;\n// //     });\n// //   }, [videoState]);\n// //\n// //   return (\n// //     <div>\n// //       <button onClick={setVideoState}>CLICK</button>\n// //       <div className=\"video-box center\">\n// //         <video ref={videoRef} autoPlay/>\n// //       </div>\n// //     </div>\n// //   );\n// // }\n//\n// export default Stream;\n//\n//\n\nvar _c;\n\n$RefreshReg$(_c, \"Stream\");","map":{"version":3,"names":["faceapi","React","Stream","modelsLoaded","setModelsLoaded","useState","captureVideo","setCaptureVideo","videoRef","useRef","videoHeight","videoWidth","canvasRef","useEffect","loadModels","MODEL_URL","process","env","PUBLIC_URL","Promise","all","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","startVideo","navigator","mediaDevices","getUserMedia","video","width","stream","current","srcObject","play","catch","err","console","error","handleVideoOnPlay","setInterval","innerHTML","createCanvasFromMedia","displaySize","height","matchDimensions","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions","closeWebcam","pause","getTracks","stop","textAlign","padding","cursor","backgroundColor","color","fontSize","border","borderRadius","display","justifyContent","position"],"sources":["/Users/maraclupanciuc/Desktop/SmartBrain/face-detection/face_detection/src/components/Stream/Stream.jsx"],"sourcesContent":["import * as faceapi from 'face-api.js';\nimport React from 'react';\n\nfunction Stream() {\n\n  const [modelsLoaded, setModelsLoaded] = React.useState(false);\n  const [captureVideo, setCaptureVideo] = React.useState(false);\n\n  const videoRef = React.useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = React.useRef();\n\n  React.useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + '/models';\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n      ]).then(setModelsLoaded(true));\n    }\n    loadModels();\n  }, []);\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then(stream => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch(err => {\n        console.error(\"error:\", err);\n      });\n  }\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(videoRef.current);\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight\n        }\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        canvasRef && canvasRef.current && canvasRef.current.getContext('2d').clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef && canvasRef.current && faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef && canvasRef.current && faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef && canvasRef.current && faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections);\n      }\n    }, 100)\n  }\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  }\n\n  return (\n    <div>\n      <div style={{ textAlign: 'center', padding: '10px' }}>\n        {\n          captureVideo && modelsLoaded ?\n            <button onClick={closeWebcam} style={{ cursor: 'pointer', backgroundColor: 'green', color: 'white', padding: '15px', fontSize: '25px', border: 'none', borderRadius: '10px' }}>\n              Close Webcam\n            </button>\n            :\n            <button onClick={startVideo} style={{ cursor: 'pointer', backgroundColor: 'green', color: 'white', padding: '15px', fontSize: '25px', border: 'none', borderRadius: '10px' }}>\n              Open Webcam\n            </button>\n        }\n      </div>\n      {\n        captureVideo ?\n          modelsLoaded ?\n            <div>\n              <div style={{ display: 'flex', justifyContent: 'center', padding: '10px' }}>\n                <video ref={videoRef} height={videoHeight} width={videoWidth} onPlay={handleVideoOnPlay} style={{ borderRadius: '10px' }} />\n                <canvas ref={canvasRef} style={{ position: 'absolute' }} />\n              </div>\n            </div>\n            :\n            <div>loading...</div>\n          :\n          <>\n          </>\n      }\n    </div>\n  );\n}\nexport default Stream;\n// import {useRef, useEffect, useState} from \"react\";\n// import './stream.css'\n// import * as faceapi from 'face-api.js';import '../../face-api.min'\n// // import {faceapi} from \"../../face-api.min\";\n//\n//\n// const Stream = ({videoState, setVideoState}) => {\n//\n//   const videoRef = useRef();\n//   const [modelsLoaded, setModelsLoaded] = useState(false);\n//   const [captureVideo, setCaptureVideo] = useState(false);\n//\n//   useEffect(() => {\n//     const loadModels = async () => {\n//       const MODEL_URL = process.env.PUBLIC_URL + '../../models';\n//\n//       Promise.all([\n//         faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n//         faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n//         faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n//         faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n//       ]).then(setModelsLoaded(true));\n//     }\n//     loadModels();\n//   }, []);\n//   return (\n//     <div>\n//\n//     </div>\n//   )\n// }\n// //   useEffect(() => {\n// //     navigator.mediaDevices.getUserMedia({ video: videoState }).then((stream) => {\n// //       videoRef.current.srcObject = stream;\n// //     });\n// //   }, [videoState]);\n// //\n// //   return (\n// //     <div>\n// //       <button onClick={setVideoState}>CLICK</button>\n// //       <div className=\"video-box center\">\n// //         <video ref={videoRef} autoPlay/>\n// //       </div>\n// //     </div>\n// //   );\n// // }\n//\n// export default Stream;\n//\n//\n"],"mappings":";;;AAAA,OAAO,KAAKA,OAAZ,MAAyB,aAAzB;AACA,OAAOC,KAAP,MAAkB,OAAlB;;;;AAEA,SAASC,MAAT,GAAkB;EAAA;;EAEhB,MAAM,CAACC,YAAD,EAAeC,eAAf,IAAkCH,KAAK,CAACI,QAAN,CAAe,KAAf,CAAxC;EACA,MAAM,CAACC,YAAD,EAAeC,eAAf,IAAkCN,KAAK,CAACI,QAAN,CAAe,KAAf,CAAxC;EAEA,MAAMG,QAAQ,GAAGP,KAAK,CAACQ,MAAN,EAAjB;EACA,MAAMC,WAAW,GAAG,GAApB;EACA,MAAMC,UAAU,GAAG,GAAnB;EACA,MAAMC,SAAS,GAAGX,KAAK,CAACQ,MAAN,EAAlB;EAEAR,KAAK,CAACY,SAAN,CAAgB,MAAM;IACpB,MAAMC,UAAU,GAAG,YAAY;MAC7B,MAAMC,SAAS,GAAGC,OAAO,CAACC,GAAR,CAAYC,UAAZ,GAAyB,SAA3C;MAEAC,OAAO,CAACC,GAAR,CAAY,CACVpB,OAAO,CAACqB,IAAR,CAAaC,gBAAb,CAA8BC,WAA9B,CAA0CR,SAA1C,CADU,EAEVf,OAAO,CAACqB,IAAR,CAAaG,iBAAb,CAA+BD,WAA/B,CAA2CR,SAA3C,CAFU,EAGVf,OAAO,CAACqB,IAAR,CAAaI,kBAAb,CAAgCF,WAAhC,CAA4CR,SAA5C,CAHU,EAIVf,OAAO,CAACqB,IAAR,CAAaK,iBAAb,CAA+BH,WAA/B,CAA2CR,SAA3C,CAJU,CAAZ,EAKGY,IALH,CAKQvB,eAAe,CAAC,IAAD,CALvB;IAMD,CATD;;IAUAU,UAAU;EACX,CAZD,EAYG,EAZH;;EAcA,MAAMc,UAAU,GAAG,MAAM;IACvBrB,eAAe,CAAC,IAAD,CAAf;IACAsB,SAAS,CAACC,YAAV,CACGC,YADH,CACgB;MAAEC,KAAK,EAAE;QAAEC,KAAK,EAAE;MAAT;IAAT,CADhB,EAEGN,IAFH,CAEQO,MAAM,IAAI;MACd,IAAIF,KAAK,GAAGxB,QAAQ,CAAC2B,OAArB;MACAH,KAAK,CAACI,SAAN,GAAkBF,MAAlB;MACAF,KAAK,CAACK,IAAN;IACD,CANH,EAOGC,KAPH,CAOSC,GAAG,IAAI;MACZC,OAAO,CAACC,KAAR,CAAc,QAAd,EAAwBF,GAAxB;IACD,CATH;EAUD,CAZD;;EAcA,MAAMG,iBAAiB,GAAG,MAAM;IAC9BC,WAAW,CAAC,YAAY;MACtB,IAAI/B,SAAS,IAAIA,SAAS,CAACuB,OAA3B,EAAoC;QAClCvB,SAAS,CAACuB,OAAV,CAAkBS,SAAlB,GAA8B5C,OAAO,CAAC6C,qBAAR,CAA8BrC,QAAQ,CAAC2B,OAAvC,CAA9B;QACA,MAAMW,WAAW,GAAG;UAClBb,KAAK,EAAEtB,UADW;UAElBoC,MAAM,EAAErC;QAFU,CAApB;QAKAV,OAAO,CAACgD,eAAR,CAAwBpC,SAAS,CAACuB,OAAlC,EAA2CW,WAA3C;QAEA,MAAMG,UAAU,GAAG,MAAMjD,OAAO,CAACkD,cAAR,CAAuB1C,QAAQ,CAAC2B,OAAhC,EAAyC,IAAInC,OAAO,CAACmD,uBAAZ,EAAzC,EAAgFC,iBAAhF,GAAoGC,mBAApG,EAAzB;QAEA,MAAMC,iBAAiB,GAAGtD,OAAO,CAACuD,aAAR,CAAsBN,UAAtB,EAAkCH,WAAlC,CAA1B;QAEAlC,SAAS,IAAIA,SAAS,CAACuB,OAAvB,IAAkCvB,SAAS,CAACuB,OAAV,CAAkBqB,UAAlB,CAA6B,IAA7B,EAAmCC,SAAnC,CAA6C,CAA7C,EAAgD,CAAhD,EAAmD9C,UAAnD,EAA+DD,WAA/D,CAAlC;QACAE,SAAS,IAAIA,SAAS,CAACuB,OAAvB,IAAkCnC,OAAO,CAAC0D,IAAR,CAAaC,cAAb,CAA4B/C,SAAS,CAACuB,OAAtC,EAA+CmB,iBAA/C,CAAlC;QACA1C,SAAS,IAAIA,SAAS,CAACuB,OAAvB,IAAkCnC,OAAO,CAAC0D,IAAR,CAAaE,iBAAb,CAA+BhD,SAAS,CAACuB,OAAzC,EAAkDmB,iBAAlD,CAAlC;QACA1C,SAAS,IAAIA,SAAS,CAACuB,OAAvB,IAAkCnC,OAAO,CAAC0D,IAAR,CAAaG,mBAAb,CAAiCjD,SAAS,CAACuB,OAA3C,EAAoDmB,iBAApD,CAAlC;MACD;IACF,CAnBU,EAmBR,GAnBQ,CAAX;EAoBD,CArBD;;EAuBA,MAAMQ,WAAW,GAAG,MAAM;IACxBtD,QAAQ,CAAC2B,OAAT,CAAiB4B,KAAjB;IACAvD,QAAQ,CAAC2B,OAAT,CAAiBC,SAAjB,CAA2B4B,SAA3B,GAAuC,CAAvC,EAA0CC,IAA1C;IACA1D,eAAe,CAAC,KAAD,CAAf;EACD,CAJD;;EAMA,oBACE;IAAA,wBACE;MAAK,KAAK,EAAE;QAAE2D,SAAS,EAAE,QAAb;QAAuBC,OAAO,EAAE;MAAhC,CAAZ;MAAA,UAEI7D,YAAY,IAAIH,YAAhB,gBACE;QAAQ,OAAO,EAAE2D,WAAjB;QAA8B,KAAK,EAAE;UAAEM,MAAM,EAAE,SAAV;UAAqBC,eAAe,EAAE,OAAtC;UAA+CC,KAAK,EAAE,OAAtD;UAA+DH,OAAO,EAAE,MAAxE;UAAgFI,QAAQ,EAAE,MAA1F;UAAkGC,MAAM,EAAE,MAA1G;UAAkHC,YAAY,EAAE;QAAhI,CAArC;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QADF,gBAKE;QAAQ,OAAO,EAAE7C,UAAjB;QAA6B,KAAK,EAAE;UAAEwC,MAAM,EAAE,SAAV;UAAqBC,eAAe,EAAE,OAAtC;UAA+CC,KAAK,EAAE,OAAtD;UAA+DH,OAAO,EAAE,MAAxE;UAAgFI,QAAQ,EAAE,MAA1F;UAAkGC,MAAM,EAAE,MAA1G;UAAkHC,YAAY,EAAE;QAAhI,CAApC;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA;IAPN;MAAA;MAAA;MAAA;IAAA,QADF,EAcInE,YAAY,GACVH,YAAY,gBACV;MAAA,uBACE;QAAK,KAAK,EAAE;UAAEuE,OAAO,EAAE,MAAX;UAAmBC,cAAc,EAAE,QAAnC;UAA6CR,OAAO,EAAE;QAAtD,CAAZ;QAAA,wBACE;UAAO,GAAG,EAAE3D,QAAZ;UAAsB,MAAM,EAAEE,WAA9B;UAA2C,KAAK,EAAEC,UAAlD;UAA8D,MAAM,EAAE+B,iBAAtE;UAAyF,KAAK,EAAE;YAAE+B,YAAY,EAAE;UAAhB;QAAhG;UAAA;UAAA;UAAA;QAAA,QADF,eAEE;UAAQ,GAAG,EAAE7D,SAAb;UAAwB,KAAK,EAAE;YAAEgE,QAAQ,EAAE;UAAZ;QAA/B;UAAA;UAAA;UAAA;QAAA,QAFF;MAAA;QAAA;QAAA;QAAA;MAAA;IADF;MAAA;MAAA;MAAA;IAAA,QADU,gBAQV;MAAA;IAAA;MAAA;MAAA;MAAA;IAAA,QATQ,gBAWV,qCAzBN;EAAA;IAAA;IAAA;IAAA;EAAA,QADF;AA+BD;;GAlGQ1E,M;;KAAAA,M;AAmGT,eAAeA,MAAf,C,CACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA"},"metadata":{},"sourceType":"module"}